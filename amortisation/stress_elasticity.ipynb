{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7956c1",
   "metadata": {},
   "source": [
    "## How sensitive is ES to systemic coupling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import ncx2\n",
    "from scipy.special import hyp1f1\n",
    "from scipy.optimize import brentq\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "DECIMALS = 6\n",
    "\n",
    "np.set_printoptions(precision=DECIMALS, suppress=True)\n",
    "pd.options.display.float_format = lambda x: f\"{x:.{DECIMALS}f}\"\n",
    "pd.set_option(\"display.precision\", DECIMALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924204da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_max_generator(epsilon, y, theta, sigma, kappa, max_attempts=5, tol=1e-8):\n",
    "    \"\"\"\n",
    "    \n",
    "    Compute H^*_epsilon such that P_y(sigma_H < tau) = G_y(H; H) <= epsilon.\n",
    "    This function implements Equation (11) using the closed-form in Equation (19).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def G_y(H):\n",
    "\n",
    "        a = H / kappa  # Now using H as the Laplace exponent (since tau ~ Exp(H))\n",
    "        b = 2 * kappa * theta / sigma**2\n",
    "        z_y = 2 * kappa * y / sigma**2\n",
    "        z_H = 2 * kappa * H / sigma**2\n",
    "\n",
    "        num = hyp1f1(a, b, z_y)\n",
    "        denom = hyp1f1(a, b, z_H)\n",
    "        \n",
    "        return num / denom  # This is G_y(H; H) = E[e^{-H * sigma_H}]\n",
    "\n",
    "    def root_function(H):\n",
    "        return G_y(H) - epsilon\n",
    "\n",
    "    # Bracketing interval\n",
    "    H_min = y + 1e-8\n",
    "    H_max = y + 10.0\n",
    "\n",
    "    # Expand H_max until G_y(H_max) < epsilon\n",
    "    for _ in range(max_attempts):\n",
    "        try:\n",
    "          H_star = scipy.optimize.toms748(root_function, H_min, H_max, xtol=tol)\n",
    "          \n",
    "          if root_function(H_star)<=0:\n",
    "            \n",
    "            return H_star\n",
    "          \n",
    "          else:\n",
    "          \n",
    "            while root_function(H_star)>0:\n",
    "              H_star = H_star + 1e-2\n",
    "          \n",
    "            return H_star\n",
    "          \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        H_max += 5.0\n",
    "\n",
    "    # Fallback: scan manually to find conservative H\n",
    "    print(\"[Warning] brentq failed to converge. Using fallback grid search.\")\n",
    "    H_vals = np.linspace(H_min, H_max + 50, 1000)\n",
    "    for H in H_vals:\n",
    "        if G_y(H) <= epsilon:\n",
    "            return H\n",
    "\n",
    "    raise RuntimeError(\"Unable to find H^*_epsilon. Try expanding search space.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cir_transition_sample_per_sector(y_vec, tau, kappa_vec, theta_vec, sigma_vec, rng):\n",
    "    \"\"\"\n",
    "    y_vec, kappa_vec, theta_vec, sigma_vec are arrays of length J (sectors).\n",
    "    Returns xi_vec: sampled Y_{t+tau} per sector (length J).\n",
    "    \"\"\"\n",
    "    if tau <= 0:\n",
    "        return y_vec.copy()\n",
    "    \n",
    "    one_minus = -np.expm1(-kappa_vec * tau)  # = 1 - exp(-kappa*tau)\n",
    "    # avoid zeros\n",
    "    one_minus = np.where(one_minus <= 0, 1e-16, one_minus)\n",
    "    \n",
    "    c = (sigma_vec * sigma_vec * one_minus) / (4.0 * kappa_vec)\n",
    "    d = 4.0 * kappa_vec * theta_vec / (sigma_vec * sigma_vec)\n",
    "    \n",
    "    # noncentrality parameters\n",
    "    nc = (4.0 * kappa_vec * np.exp(-kappa_vec * tau) * y_vec) / (sigma_vec * sigma_vec * one_minus)\n",
    "    \n",
    "    # guard\n",
    "    d = np.maximum(d, 1e-12)\n",
    "    nc = np.maximum(nc, 0.0)\n",
    "    \n",
    "    # sample per sector (simple looping works fine since J would be typically small)\n",
    "    xi = np.empty_like(y_vec, dtype=float)\n",
    "\n",
    "    for j in range(len(y_vec)):\n",
    "    \n",
    "        # If df or nc are extreme, ncx2.rvs might throw an error\n",
    "        try:\n",
    "            Z = ncx2.rvs(df=d[j], nc=nc[j], random_state=rng)\n",
    "    \n",
    "        except Exception:\n",
    "            Z = ncx2.rvs(df=max(d[j],1e-6), nc=0.0, random_state=rng) + nc[j]\n",
    "    \n",
    "        xi[j] = c[j] * Z\n",
    "    \n",
    "    xi = np.maximum(xi, 0.0)\n",
    "    \n",
    "    return xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43313bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGD_MEAN = 0.45\n",
    "LGD_STD = 0.15\n",
    "\n",
    "def get_beta_params(mu, sigma):\n",
    "    if sigma**2 >= mu * (1 - mu):\n",
    "        raise ValueError(\"Standard deviation is too high for this mean.\")\n",
    "\n",
    "    nu = (mu * (1 - mu) / sigma**2) - 1\n",
    "    alpha = mu * nu\n",
    "    beta = (1 - mu) * nu\n",
    "    return alpha, beta\n",
    "\n",
    "alpha_lgd, beta_lgd = get_beta_params(LGD_MEAN, LGD_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_lgd, beta_lgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e837d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def loss_distribution_plot(Payoff_T,index):\n",
    "  # Get histogram data (without plotting)\n",
    "  counts, bin_edges = np.histogram(Payoff_T, bins=10, density=True)\n",
    "\n",
    "  # Get bin centers\n",
    "  bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "  # Interpolation function\n",
    "  f_interp = interp1d(bin_centers, counts, kind='cubic', fill_value=\"extrapolate\")\n",
    "\n",
    "  # New x-values for smooth curve\n",
    "  x_smooth = np.linspace(bin_centers.min(), bin_centers.max(), 500)\n",
    "  y_smooth = f_interp(x_smooth)\n",
    "\n",
    "  # Plot histogram and interpolated curve\n",
    "  plt.hist(Payoff_T, bins=100, density=True, label='Histogram_'+str(index),alpha = 0.4)\n",
    "  plt.plot(x_smooth, y_smooth, label='Loss Distribution Case_'+str(index))\n",
    "  plt.xlabel('Loss')\n",
    "  plt.ylabel('Density')\n",
    "  # plt.legend()\n",
    "  plt.title('Loss Distribution for '+str(index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2470007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_shortfall(losses, alpha=0.95):\n",
    "    var_alpha = np.quantile(losses, alpha)\n",
    "    tail_losses = losses[losses >= var_alpha]\n",
    "    return float(np.round(tail_losses.mean(), DECIMALS))\n",
    "\n",
    "def compute_metrics(losses, alpha=0.95):\n",
    "    var_alpha = np.quantile(losses, alpha)\n",
    "    es = expected_shortfall(losses, alpha)\n",
    "    metrics = {\n",
    "        \"Mean\": np.mean(losses),\n",
    "        \"Std\": np.std(losses),\n",
    "        \"VaR\": var_alpha,\n",
    "        \"ES\": es,\n",
    "        \"Excess ES\": es - var_alpha,\n",
    "        \"ExcessKurtosis\": kurtosis(losses)\n",
    "    }\n",
    "    return {key: float(np.round(value, DECIMALS)) for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_types = [\"bullet\", \"linear\", \"french\", \"negative\"]\n",
    "\n",
    "def bullet_exposure(contract, T, t):\n",
    "    P = float(contract[\"P\"])\n",
    "    return P if t < T else 0.0\n",
    "\n",
    "\n",
    "def linear_exposure(contract, T, t):\n",
    "    P = float(contract[\"P\"])\n",
    "    periods_per_year = float(contract[\"N\"])\n",
    "    if periods_per_year <= 0 or T <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    period = 1.0 / periods_per_year  # years per period\n",
    "    total_periods = int(np.ceil(T * periods_per_year))\n",
    "    payments_made = int(np.floor(t / period))\n",
    "    payments_made = int(np.clip(payments_made, 0, total_periods))\n",
    "    principal_paid = (payments_made / total_periods) * P\n",
    "    return max(P - principal_paid, 0.0)\n",
    "\n",
    "\n",
    "def french_exposure(contract, T, t):\n",
    "    P = float(contract[\"P\"])\n",
    "    periods_per_year = float(contract[\"N\"])\n",
    "    r_annual = float(contract[\"r\"])\n",
    "    if periods_per_year <= 0 or T <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    period = 1.0 / periods_per_year  # years per period\n",
    "    total_periods = int(np.ceil(T * periods_per_year))\n",
    "    payments_made = int(np.floor(t / period))\n",
    "    payments_made = int(np.clip(payments_made, 0, total_periods))\n",
    "    periods_remaining = total_periods - payments_made\n",
    "    if periods_remaining <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    r_period = r_annual / periods_per_year  # annual to per-period rate\n",
    "\n",
    "    if r_period == 0.0:\n",
    "        payment = P / total_periods\n",
    "        return payment * periods_remaining\n",
    "\n",
    "    annuity_payment = P * r_period / (1.0 - (1.0 + r_period) ** (-total_periods))\n",
    "    pv_remaining = annuity_payment * (1.0 - (1.0 + r_period) ** (-periods_remaining)) / r_period\n",
    "    return pv_remaining\n",
    "\n",
    "\n",
    "def negative_amortization_exposure(contract, T, t):\n",
    "    P = float(contract[\"P\"])\n",
    "    periods_per_year = float(contract[\"N\"])\n",
    "    r_annual = float(contract.get(\"r\", 0.0))\n",
    "    if periods_per_year <= 0 or T <= 0:\n",
    "        return max(P, 0.0)\n",
    "\n",
    "    period = 1.0 / periods_per_year  # years per period\n",
    "    total_periods = int(np.ceil(T * periods_per_year))\n",
    "    periods_elapsed = int(np.floor(t / period))\n",
    "    periods_elapsed = int(np.clip(periods_elapsed, 0, total_periods))\n",
    "\n",
    "    r_period = r_annual / periods_per_year  # annual to per-period rate\n",
    "\n",
    "    exposure = P * ((1.0 + r_period) ** periods_elapsed)\n",
    "\n",
    "    return exposure if t < T else 0.0\n",
    "\n",
    "\n",
    "def exposure_at_time(contract, T, t):\n",
    "    loan_type = str(contract[\"type\"]).lower()\n",
    "    dispatch = {\n",
    "        \"bullet\": bullet_exposure,\n",
    "        \"linear\": linear_exposure,\n",
    "        \"french\": french_exposure,\n",
    "        \"negative_amortisation\": negative_amortization_exposure,\n",
    "    }\n",
    "    if loan_type not in dispatch:\n",
    "        raise ValueError(f\"Unknown loan type: {loan_type}\")\n",
    "    return dispatch[loan_type](contract, T, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sector_cir_model(kappa, theta, sigma, T, delta, W, eps, lambda_benchmark,\n",
    "                              Nfirms, idiosyncratic_factor, loan_contracts, alpha_lgd, beta_lgd, rng=None):\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # ensure shapes\n",
    "    J = len(theta)\n",
    "    assert W.shape == (Nfirms, J)\n",
    "    idiosyncratic_factor = np.asarray(idiosyncratic_factor).reshape(Nfirms,)\n",
    "    lambda_benchmark = np.asarray(lambda_benchmark).reshape(J,)\n",
    "\n",
    "    delta = np.asarray(delta)\n",
    "    if delta.ndim == 1:\n",
    "        delta = np.tile(delta.reshape(1, J), (Nfirms, 1))\n",
    "    assert delta.shape == (Nfirms, J)\n",
    "\n",
    "    # init\n",
    "    t = 0.0\n",
    "    Y_t = theta.copy().astype(float)   # sectoral intensities (J-vector), initialised at theta\n",
    "    events = []\n",
    "    owed = []\n",
    "    marks = []\n",
    "    defaulter_idio_factor = []\n",
    "    sector_contributions = []\n",
    "    alive = np.arange(Nfirms, dtype=int)\n",
    "\n",
    "    # precompute some arrays for speed\n",
    "    kappa = np.asarray(kappa, dtype=float)\n",
    "    sigma = np.asarray(sigma, dtype=float)\n",
    "    theta = np.asarray(theta, dtype=float)\n",
    "\n",
    "    # event loop\n",
    "    while (t < T) and (alive.size > 0):\n",
    "\n",
    "        lambda_max = np.maximum(Y_t, lambda_benchmark)  # J-vector\n",
    "        # Hepsilon = sum_i [ X_i + w_i Â· lambda_max ] over alive firms\n",
    "        \n",
    "        # We can compute per-firm value and sum\n",
    "        per_firm_sys = W[alive].dot(lambda_max)   # length alive.size\n",
    "        per_firm_idio = idiosyncratic_factor[alive]\n",
    "        Hepsilon = per_firm_sys.sum() + per_firm_idio.sum()\n",
    "\n",
    "        if Hepsilon <= 0:\n",
    "            break\n",
    "\n",
    "        # sample a candidate waiting time\n",
    "        tau = rng.exponential(1.0 / Hepsilon)\n",
    "        t_candidate = t + tau\n",
    "        if t_candidate >= T:\n",
    "            break\n",
    "\n",
    "        # sample sectoral Y at t_candidate conditional on no defaults in the waiting time\n",
    "        Y_proposed = cir_transition_sample_per_sector(Y_t, tau, kappa, theta, sigma, rng)\n",
    "\n",
    "        # compute proposed per-firm intensities (scalar values) using Y_proposed\n",
    "        per_firm_sys_prop = W[alive].dot(Y_proposed)\n",
    "        per_firm_total_prop = per_firm_sys_prop + per_firm_idio\n",
    "        lambda_proposed_total = per_firm_total_prop.sum()\n",
    "\n",
    "        # acceptance probability: Xi / Hepsilon where Xi = lambda_proposed_total\n",
    "        accept_prob = min(lambda_proposed_total / Hepsilon, 1.0)\n",
    "        if rng.random() < accept_prob:\n",
    "            # accept a default at t_candidate\n",
    "            t = t_candidate\n",
    "            events.append(t)\n",
    "\n",
    "            # choose which alive firm defaulted\n",
    "            probs = per_firm_total_prop / lambda_proposed_total\n",
    "            probs = np.maximum(probs, 0.0)\n",
    "            probs = probs / probs.sum()\n",
    "            selected_local_idx = rng.choice(len(alive), p=probs)\n",
    "            selected_firm = int(alive[selected_local_idx])\n",
    "\n",
    "            # record idiosyncratic factor\n",
    "            defaulter_idio_factor.append(float(idiosyncratic_factor[selected_firm]))\n",
    "\n",
    "            sector_contributions.append(W[selected_firm].copy())\n",
    "\n",
    "            # mark (loss) from contract exposure\n",
    "            contract = loan_contracts[selected_firm]\n",
    "            exposure = exposure_at_time(contract, T, t)\n",
    "            if exposure < 0:\n",
    "                warnings.warn(\"Exposure computed negative; clamping to zero.\")\n",
    "                exposure = max(exposure, 0.0)\n",
    "            if t >= T and exposure > 0:\n",
    "                warnings.warn(\"Exposure positive after maturity; forcing to zero.\")\n",
    "                exposure = 0.0\n",
    "\n",
    "            owed.append(exposure)\n",
    "            \n",
    "            LGD = rng.beta(alpha_lgd, beta_lgd)\n",
    "            mark = LGD * exposure\n",
    "            # mark =  exposure\n",
    "            if mark < 0:\n",
    "                warnings.warn(\"Loss mark negative; clamping to zero.\")\n",
    "                mark = max(mark, 0.0)\n",
    "            marks.append(mark)\n",
    "\n",
    "            # update Y_t with contagion\n",
    "            Y_t = Y_proposed + delta[selected_firm] * mark/contract[\"P\"]\n",
    "\n",
    "            # remove defaulted firm from alive set\n",
    "            alive = np.delete(alive, selected_local_idx)\n",
    "\n",
    "        else:\n",
    "            # reject, ie no default: advance time and set Y_t = Y_proposed\n",
    "            t = t_candidate\n",
    "            Y_t = Y_proposed\n",
    "\n",
    "    return (np.array(events), np.array(marks), np.array(owed),\n",
    "            np.array(defaulter_idio_factor), np.array(sector_contributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_portfolio_weights(N, J, composition_type, concentration_params=None, rng=None):\n",
    "    \"\"\"\n",
    "    Build portfolio weights under three stylised configurations plus a random fallback.\n",
    "\n",
    "    - concentrated: one dominant sector for every obligor (eg for J=3 [0.7, 0.2, 0.1])\n",
    "    - balanced: evenly distributed across sectors (eg for J=3  [1/3, 1/3, 1/3])\n",
    "    - mixed: partial concentration with residual diversified weights (eg for J=3  [0.5, 0.3, 0.2])\n",
    "    - random: symmetric Dirichlet for variation.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    if concentration_params is None:\n",
    "        concentration_params = {}\n",
    "\n",
    "    noise_level = concentration_params.get(\"noise_level\", 0.0)\n",
    "    alpha_random = concentration_params.get(\"alpha\", 1.0)\n",
    "\n",
    "    if composition_type == \"concentrated\":\n",
    "        pattern = _pattern_concentrated(J)\n",
    "        W = _apply_noise_and_normalize(pattern, N, noise_level, rng)\n",
    "    elif composition_type == \"balanced\":\n",
    "        pattern = _pattern_balanced(J)\n",
    "        W = _apply_noise_and_normalize(pattern, N, noise_level, rng)\n",
    "    elif composition_type == \"mixed\":\n",
    "        pattern = _pattern_mixed(J)\n",
    "        W = _apply_noise_and_normalize(pattern, N, noise_level, rng)\n",
    "    elif composition_type == \"random\":\n",
    "        W = _generate_random_weights(N, J, {\"alpha\": alpha_random}, rng)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown composition_type: {composition_type}\")\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def _pattern_concentrated(J, dominant=0.7):\n",
    "    if J <= 0:\n",
    "        return np.array([])\n",
    "    if J == 1:\n",
    "        return np.array([1.0])\n",
    "    residual = max(1.0 - dominant, 0.0)\n",
    "    tail = residual / (J - 1)\n",
    "    vec = np.full(J, tail)\n",
    "    vec[0] = dominant\n",
    "    return vec\n",
    "\n",
    "\n",
    "def _pattern_balanced(J):\n",
    "    if J <= 0:\n",
    "        return np.array([])\n",
    "    return np.full(J, 1.0 / J)\n",
    "\n",
    "\n",
    "def _pattern_mixed(J, primary=0.5, secondary=0.3):\n",
    "    if J <= 0:\n",
    "        return np.array([])\n",
    "    vec = np.zeros(J)\n",
    "    vec[0] = min(primary, 1.0)\n",
    "    if J >= 2:\n",
    "        vec[1] = min(secondary, max(1.0 - vec[0], 0.0))\n",
    "    residual = max(1.0 - vec.sum(), 0.0)\n",
    "    if J > 2:\n",
    "        vec[2:] = residual / (J - 2)\n",
    "    elif J == 1:\n",
    "        vec[0] = 1.0\n",
    "    else:\n",
    "        vec[1] += residual\n",
    "    return vec\n",
    "\n",
    "\n",
    "def _apply_noise_and_normalize(pattern, N, noise_level, rng):\n",
    "    base = np.tile(pattern, (N, 1))\n",
    "    if noise_level > 0:\n",
    "        noise = rng.normal(0.0, noise_level, size=base.shape)\n",
    "        base = base + noise\n",
    "    base = np.maximum(base, 1e-6)\n",
    "    base = base / base.sum(axis=1, keepdims=True)\n",
    "    return base\n",
    "\n",
    "\n",
    "def _generate_random_weights(N, J, params, rng):\n",
    "    alpha = params.get(\"alpha\", 1.0)\n",
    "    W = np.zeros((N, J))\n",
    "    for i in range(N):\n",
    "        W[i] = rng.dirichlet(np.full(J, alpha))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45741ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(params, loan_contracts, num_trials, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    eps = 1e-5\n",
    "    losses = np.zeros(num_trials)\n",
    "    for i in range(num_trials):\n",
    "        events, marks, _, _, _ = simulate_sector_cir_model(params['kappa'], params['theta'], params['sigma'], \n",
    "                          params['T'], params['delta'], params['W'], 1e-5, \n",
    "                          params['lambda_benchmark'], \n",
    "                          params['Firms'], params['idio_factor'], \n",
    "                          loan_contracts, alpha_lgd, beta_lgd,\n",
    "                          rng)\n",
    "        losses[i] = np.sum(marks)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ES_c_curve_with_CI(\n",
    "    params,\n",
    "    loan_contracts,\n",
    "    c_values,\n",
    "    num_trials=4000,\n",
    "    alpha=0.95,\n",
    "    seed=42,\n",
    "    num_batches=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes mean ES(c) with simple Monte Carlo error bars\n",
    "    using batching.\n",
    "\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    batch_size = num_trials // num_batches\n",
    "    ES_mean = []\n",
    "    ES_std = []\n",
    "\n",
    "    for c in c_values:\n",
    "        params_c = params.copy()\n",
    "        params_c[\"delta\"] = c * params[\"delta\"]\n",
    "\n",
    "        ES_batches = []\n",
    "\n",
    "        for b in range(num_batches):\n",
    "            losses = run_simulation(\n",
    "                params_c,\n",
    "                loan_contracts,\n",
    "                num_trials=batch_size,\n",
    "                seed=rng.integers(1e9)\n",
    "            )\n",
    "            ES_batches.append(expected_shortfall(losses, alpha))\n",
    "\n",
    "        ES_mean.append(np.mean(ES_batches))\n",
    "        ES_std.append(np.std(ES_batches))\n",
    "\n",
    "    return np.array(ES_mean), np.array(ES_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ES_c_curves(\n",
    "    c_values,\n",
    "    ES_dict,\n",
    "    ES_std_dict=None\n",
    "):\n",
    "    \"\"\"\n",
    "    ES_dict: {label: ES_values}\n",
    "    ES_std_dict (optional): {label: std_values}\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "\n",
    "    for label, ES_vals in ES_dict.items():\n",
    "        plt.plot(c_values, ES_vals, marker=\"o\", label=label)\n",
    "\n",
    "        if ES_std_dict is not None:\n",
    "            std = ES_std_dict[label]\n",
    "            plt.fill_between(\n",
    "                c_values,\n",
    "                ES_vals - std,\n",
    "                ES_vals + std,\n",
    "                alpha=0.2\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Contagion Coupling Strength $c$\")\n",
    "    plt.ylabel(\"Expected Shortfall (95%)\")\n",
    "    plt.title(\"Tail Risk Sensitivity to Systemic Coupling\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d9ce9",
   "metadata": {},
   "source": [
    "## Balanced sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1265883927568217)\n",
    "\n",
    "N_firms = 1000\n",
    "J = 3\n",
    "\n",
    "c = 0.01\n",
    "\n",
    "T = 2\n",
    "\n",
    "NUM_TRIALS = 2500\n",
    "\n",
    "kappa = rng.uniform(0.5, 1.5, J)\n",
    "theta = rng.uniform(0.001, 0.051, J)\n",
    "sigma_inter = rng.uniform(0.0, 0.2, J)\n",
    "sigma = np.minimum(np.sqrt(2*kappa*theta), sigma_inter)\n",
    "\n",
    "idio_factor = rng.uniform(0.01, 0.03, N_firms)\n",
    "\n",
    "feller = (2 * kappa * theta) / (sigma**2)\n",
    "print(\"Feller condition (should be >=1):\", feller)\n",
    "\n",
    "W = generate_portfolio_weights(N_firms, J, \"balanced\", rng=rng)\n",
    "\n",
    "delta = c * W\n",
    "\n",
    "lambda_benchmark = np.array([\n",
    "    lambda_max_generator(1e-4, theta[j], theta[j],\n",
    "                         sigma[j], kappa[j])\n",
    "    for j in range(J)\n",
    "])\n",
    "\n",
    "\n",
    "params = {\n",
    "    'Firms': N_firms,\n",
    "    'Sectors': J,\n",
    "    'Global Senstivity Param': c,\n",
    "    'kappa': kappa,\n",
    "    'theta': theta,\n",
    "    'sigma': sigma,\n",
    "    'delta': delta,\n",
    "    'lambda_benchmark': lambda_benchmark,\n",
    "    'idio_factor': idio_factor,\n",
    "    'W': W,\n",
    "    'T': T\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85627e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_contracts = [\n",
    "    {\n",
    "        \"type\": \"bullet\", \n",
    "        \"P\": 10, \n",
    "        \"N\": 12, \n",
    "        \"r\": 0.12\n",
    "    } \n",
    "    for i in range(N_firms)\n",
    "]\n",
    "\n",
    "\n",
    "linear_contracts = [{\n",
    "    \"type\": \"linear\", \n",
    "    \"P\": 10, \n",
    "    \"N\": 12, \n",
    "    \"r\": 0.12\n",
    "} for i in range(N_firms)]\n",
    "\n",
    "french_contracts = [{\n",
    "    \"type\": \"french\", \n",
    "    \"P\": 10, \n",
    "    \"N\": 12, \n",
    "    \"r\": 0.12\n",
    "} for i in range(N_firms)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f63480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_mean = {}\n",
    "ES_std = {}\n",
    "\n",
    "c_vals = np.array([0.01, 0.02, 0.04, 0.06, 0.08])\n",
    "\n",
    "for label, contracts in {\n",
    "    \"Bullet\": bullet_contracts, \n",
    "    \"Linear\": linear_contracts, \n",
    "    \"French\": french_contracts\n",
    "}.items():\n",
    "\n",
    "    m, s = compute_ES_c_curve_with_CI(\n",
    "        params,\n",
    "        contracts,\n",
    "        c_vals,\n",
    "        num_trials=2500\n",
    "    )\n",
    "    ES_mean[label] = m\n",
    "    ES_std[label] = s\n",
    "\n",
    "plot_ES_c_curves(c_vals, ES_mean, ES_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0385f",
   "metadata": {},
   "source": [
    "## Concentrated sectoral regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1265883927568217)\n",
    "\n",
    "N_firms = 1000\n",
    "J = 3\n",
    "\n",
    "c = 0.01\n",
    "\n",
    "T = 2\n",
    "\n",
    "NUM_TRIALS = 2500\n",
    "\n",
    "kappa = rng.uniform(0.5, 1.5, J)\n",
    "theta = rng.uniform(0.001, 0.051, J)\n",
    "sigma_inter = rng.uniform(0.0, 0.2, J)\n",
    "sigma = np.minimum(np.sqrt(2*kappa*theta), sigma_inter)\n",
    "\n",
    "idio_factor = rng.uniform(0.01, 0.03, N_firms)\n",
    "\n",
    "feller = (2 * kappa * theta) / (sigma**2)\n",
    "print(\"Feller condition (should be >=1):\", feller)\n",
    "\n",
    "W = generate_portfolio_weights(N_firms, J, \"concentrated\", rng=rng)\n",
    "\n",
    "delta = c * W\n",
    "\n",
    "lambda_benchmark = np.array([\n",
    "    lambda_max_generator(1e-4, theta[j], theta[j],\n",
    "                         sigma[j], kappa[j])\n",
    "    for j in range(J)\n",
    "])\n",
    "\n",
    "\n",
    "params = {\n",
    "    'Firms': N_firms,\n",
    "    'Sectors': J,\n",
    "    'Global Senstivity Param': c,\n",
    "    'kappa': kappa,\n",
    "    'theta': theta,\n",
    "    'sigma': sigma,\n",
    "    'delta': delta,\n",
    "    'lambda_benchmark': lambda_benchmark,\n",
    "    'idio_factor': idio_factor,\n",
    "    'W': W,\n",
    "    'T': T\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_contracts = [\n",
    "    {\n",
    "        \"type\": \"bullet\", \n",
    "        \"P\": 10, \n",
    "        \"N\": 12, \n",
    "        \"r\": 0.12\n",
    "    } \n",
    "    for i in range(N_firms)\n",
    "]\n",
    "\n",
    "\n",
    "linear_contracts = [{\n",
    "    \"type\": \"linear\", \n",
    "    \"P\": 10, \n",
    "    \"N\": 12, \n",
    "    \"r\": 0.12\n",
    "} for i in range(N_firms)]\n",
    "\n",
    "french_contracts = [{\n",
    "    \"type\": \"french\", \n",
    "    \"P\": 10, \n",
    "    \"N\": 12, \n",
    "    \"r\": 0.12\n",
    "} for i in range(N_firms)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa88e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_mean_c = {}\n",
    "ES_std_c = {}\n",
    "\n",
    "c_vals = np.array([0.01, 0.02, 0.04, 0.06, 0.08])\n",
    "\n",
    "for label, contracts in {\n",
    "    \"Bullet\": bullet_contracts, \n",
    "    \"Linear\": linear_contracts, \n",
    "    \"French\": french_contracts\n",
    "}.items():\n",
    "\n",
    "    m, s = compute_ES_c_curve_with_CI(\n",
    "        params,\n",
    "        contracts,\n",
    "        c_vals,\n",
    "        num_trials=2500\n",
    "    )\n",
    "    ES_mean_c[label] = m\n",
    "    ES_std_c[label] = s\n",
    "\n",
    "plot_ES_c_curves(c_vals, ES_mean_c, ES_std_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
